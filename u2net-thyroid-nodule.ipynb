{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8208818,"sourceType":"datasetVersion","datasetId":4864373}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fill up the folder details\nList the respective folder path details to the variable, example has been given below","metadata":{}},{"cell_type":"code","source":"train_img_folder = \"/kaggle/input/stanford-thyroid-cine-clips-train-test-val-splits/ThyroidNodule_Segmentation/train_Images\"\ntrain_mask_folder = \"/kaggle/input/stanford-thyroid-cine-clips-train-test-val-splits/ThyroidNodule_Segmentation/train_Masks\"\ntest_img_folder= \"/kaggle/input/stanford-thyroid-cine-clips-train-test-val-splits/ThyroidNodule_Segmentation/test_Images\"\ntest_mask_folder= \"/kaggle/input/stanford-thyroid-cine-clips-train-test-val-splits/ThyroidNodule_Segmentation/test_Masks\"\nval_img_folder = \"/kaggle/input/stanford-thyroid-cine-clips-train-test-val-splits/ThyroidNodule_Segmentation/valid_Images\"\nval_mask_folder =\"/kaggle/input/stanford-thyroid-cine-clips-train-test-val-splits/ThyroidNodule_Segmentation/valid_Masks\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function, division\nimport glob\nimport torch\nimport os\nfrom skimage import io, transform, color\nimport numpy as np\nimport random\nimport math\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom PIL import Image\nimport torch.optim as optim\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.transforms as standard_transforms\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:35.973952Z","iopub.execute_input":"2024-09-19T16:48:35.974672Z","iopub.status.idle":"2024-09-19T16:48:38.722626Z","shell.execute_reply.started":"2024-09-19T16:48:35.974627Z","shell.execute_reply":"2024-09-19T16:48:38.721581Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nclass REBNCONV(nn.Module):\n    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n        super(REBNCONV,self).__init__()\n\n        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n        self.bn_s1 = nn.BatchNorm2d(out_ch)\n        self.relu_s1 = nn.ReLU(inplace=True)\n\n    def forward(self,x):\n\n        hx = x\n        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n\n        return xout\n\n## upsample tensor 'src' to have the same spatial size with tensor 'tar'\ndef _upsample_like(src,tar):\n\n    src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n\n    return src\n\n\n### RSU-7 ###\nclass RSU7(nn.Module):#UNet07DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU7,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n        hx = self.pool3(hx3)\n\n        hx4 = self.rebnconv4(hx)\n        hx = self.pool4(hx4)\n\n        hx5 = self.rebnconv5(hx)\n        hx = self.pool5(hx5)\n\n        hx6 = self.rebnconv6(hx)\n\n        hx7 = self.rebnconv7(hx6)\n\n        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n        hx6dup = _upsample_like(hx6d,hx5)\n\n        hx5d =  self.rebnconv5d(torch.cat((hx6dup,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-6 ###\nclass RSU6(nn.Module):#UNet06DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU6,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n        hx = self.pool3(hx3)\n\n        hx4 = self.rebnconv4(hx)\n        hx = self.pool4(hx4)\n\n        hx5 = self.rebnconv5(hx)\n\n        hx6 = self.rebnconv6(hx5)\n\n\n        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-5 ###\nclass RSU5(nn.Module):#UNet05DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU5,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n        hx = self.pool3(hx3)\n\n        hx4 = self.rebnconv4(hx)\n\n        hx5 = self.rebnconv5(hx4)\n\n        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-4 ###\nclass RSU4(nn.Module):#UNet04DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n\n        hx4 = self.rebnconv4(hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-4F ###\nclass RSU4F(nn.Module):#UNet04FRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4F,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx2 = self.rebnconv2(hx1)\n        hx3 = self.rebnconv3(hx2)\n\n        hx4 = self.rebnconv4(hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n\n        return hx1d + hxin\n\n\n##### U^2-Net ####\nclass U2NET(nn.Module):\n\n    def __init__(self,in_ch=3,out_ch=1):\n        super(U2NET,self).__init__()\n\n        self.stage1 = RSU7(in_ch,32,64)\n        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage2 = RSU6(64,32,128)\n        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage3 = RSU5(128,64,256)\n        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage4 = RSU4(256,128,512)\n        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage5 = RSU4F(512,256,512)\n        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage6 = RSU4F(512,256,512)\n\n        # decoder\n        self.stage5d = RSU4F(1024,256,512)\n        self.stage4d = RSU4(1024,128,256)\n        self.stage3d = RSU5(512,64,128)\n        self.stage2d = RSU6(256,32,64)\n        self.stage1d = RSU7(128,16,64)\n\n        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side3 = nn.Conv2d(128,out_ch,3,padding=1)\n        self.side4 = nn.Conv2d(256,out_ch,3,padding=1)\n        self.side5 = nn.Conv2d(512,out_ch,3,padding=1)\n        self.side6 = nn.Conv2d(512,out_ch,3,padding=1)\n\n        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n\n    def forward(self,x):\n\n        hx = x\n\n        #stage 1\n        hx1 = self.stage1(hx)\n        hx = self.pool12(hx1)\n\n        #stage 2\n        hx2 = self.stage2(hx)\n        hx = self.pool23(hx2)\n\n        #stage 3\n        hx3 = self.stage3(hx)\n        hx = self.pool34(hx3)\n\n        #stage 4\n        hx4 = self.stage4(hx)\n        hx = self.pool45(hx4)\n\n        #stage 5\n        hx5 = self.stage5(hx)\n        hx = self.pool56(hx5)\n\n        #stage 6\n        hx6 = self.stage6(hx)\n        hx6up = _upsample_like(hx6,hx5)\n\n        #-------------------- decoder --------------------\n        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n\n\n        #side output\n        d1 = self.side1(hx1d)\n\n        d2 = self.side2(hx2d)\n        d2 = _upsample_like(d2,d1)\n\n        d3 = self.side3(hx3d)\n        d3 = _upsample_like(d3,d1)\n\n        d4 = self.side4(hx4d)\n        d4 = _upsample_like(d4,d1)\n\n        d5 = self.side5(hx5d)\n        d5 = _upsample_like(d5,d1)\n\n        d6 = self.side6(hx6)\n        d6 = _upsample_like(d6,d1)\n\n        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n\n        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:38.724780Z","iopub.execute_input":"2024-09-19T16:48:38.725221Z","iopub.status.idle":"2024-09-19T16:48:38.793649Z","shell.execute_reply.started":"2024-09-19T16:48:38.725185Z","shell.execute_reply":"2024-09-19T16:48:38.792567Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = U2NET()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:38.795019Z","iopub.execute_input":"2024-09-19T16:48:38.795374Z","iopub.status.idle":"2024-09-19T16:48:39.336542Z","shell.execute_reply.started":"2024-09-19T16:48:38.795324Z","shell.execute_reply":"2024-09-19T16:48:39.335438Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n# summary(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.338810Z","iopub.execute_input":"2024-09-19T16:48:39.339137Z","iopub.status.idle":"2024-09-19T16:48:39.347955Z","shell.execute_reply.started":"2024-09-19T16:48:39.339103Z","shell.execute_reply":"2024-09-19T16:48:39.346970Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.349255Z","iopub.execute_input":"2024-09-19T16:48:39.349672Z","iopub.status.idle":"2024-09-19T16:48:39.413440Z","shell.execute_reply.started":"2024-09-19T16:48:39.349636Z","shell.execute_reply":"2024-09-19T16:48:39.412372Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"class SalObjDataset(Dataset):\n\tdef __init__(self,img_name_list,lbl_name_list,transform=None):\n        # self.root_dir = root_dir\n\t\t# self.image_name_list = glob.glob(image_dir+'*.png')\n\t\t# self.label_name_list = glob.glob(label_dir+'*.png')\n\t\tself.image_name_list = img_name_list\n\t\tself.label_name_list = lbl_name_list\n\t\tself.transform = transform\n\n\tdef __len__(self):\n\t\treturn len(self.image_name_list)\n\n\tdef __getitem__(self,idx):\n\n\t\t# image = Image.open(self.image_name_list[idx])#io.imread(self.image_name_list[idx])\n\t\t# label = Image.open(self.label_name_list[idx])#io.imread(self.label_name_list[idx])\n\n\t\timage = io.imread(self.image_name_list[idx])\n\t\timname = self.image_name_list[idx]\n\t\timidx = np.array([idx])\n\n\t\tif(0==len(self.label_name_list)):\n\t\t\tlabel_3 = np.zeros(image.shape)\n\t\telse:\n\t\t\tlabel_3 = io.imread(self.label_name_list[idx])\n\n\t\tlabel = np.zeros(label_3.shape[0:2])\n\t\tif(3==len(label_3.shape)):\n\t\t\tlabel = label_3[:,:,0]\n\t\telif(2==len(label_3.shape)):\n\t\t\tlabel = label_3\n\n\t\tif(3==len(image.shape) and 2==len(label.shape)):\n\t\t\tlabel = label[:,:,np.newaxis]\n\t\telif(2==len(image.shape) and 2==len(label.shape)):\n\t\t\timage = image[:,:,np.newaxis]\n\t\t\tlabel = label[:,:,np.newaxis]\n\n\t\tsample = {'imidx':imidx, 'image':image, 'label':label}\n\n\t\tif self.transform:\n\t\t\tsample = self.transform(sample)\n\n\t\treturn sample","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.414973Z","iopub.execute_input":"2024-09-19T16:48:39.415504Z","iopub.status.idle":"2024-09-19T16:48:39.427164Z","shell.execute_reply.started":"2024-09-19T16:48:39.415431Z","shell.execute_reply":"2024-09-19T16:48:39.426227Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Loss Function","metadata":{}},{"cell_type":"code","source":"bce_loss = nn.BCELoss(size_average=True)\n\ndef dice_coefficient(pred, target, threshold=0.5, smooth=1e-6):\n    pred = (pred > threshold).float() \n    intersection = torch.sum(pred * target)\n    union = torch.sum(pred) + torch.sum(target)\n    dice = (2. * intersection + smooth) / (union + smooth)\n    return dice\n\ndef accuracy(pred, target, threshold=0.5):  \n    pred = (pred > threshold).float()  \n    correct = torch.sum(pred == target)\n    total = target.numel()  \n    acc = correct / total\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.428304Z","iopub.execute_input":"2024-09-19T16:48:39.428639Z","iopub.status.idle":"2024-09-19T16:48:39.445198Z","shell.execute_reply.started":"2024-09-19T16:48:39.428604Z","shell.execute_reply":"2024-09-19T16:48:39.444054Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n  warnings.warn(warning.format(ret))\n","output_type":"stream"}]},{"cell_type":"code","source":"def muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v):\n\n    loss0 = bce_loss(d0,labels_v)\n    loss1 = bce_loss(d1,labels_v)\n    loss2 = bce_loss(d2,labels_v)\n    loss3 = bce_loss(d3,labels_v)\n    loss4 = bce_loss(d4,labels_v)\n    loss5 = bce_loss(d5,labels_v)\n    loss6 = bce_loss(d6,labels_v)\n    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n    return loss0 ,loss1 , loss2 , loss3 , loss4 , loss5 , loss6, loss\n\ndef muti_dice_coef_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v):\n    dice0 = dice_coefficient(d0, labels_v)\n    dice1 = dice_coefficient(d1, labels_v)\n    dice2 = dice_coefficient(d2, labels_v)\n    dice3 = dice_coefficient(d3, labels_v)\n    dice4 = dice_coefficient(d4, labels_v)\n    dice5 = dice_coefficient(d5, labels_v)\n    dice6 = dice_coefficient(d6, labels_v)\n    final_dice = dice0+dice1+dice2+dice3+dice4+dice5+dice6\n    return dice0,dice1,dice2,dice3,dice4,dice5,dice6\n\ndef multi_accuracy_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v):\n    acc0 = accuracy(d0, labels_v)\n    acc1 = accuracy(d1, labels_v)\n    acc2 = accuracy(d2, labels_v)\n    acc3 = accuracy(d3, labels_v)\n    acc4 = accuracy(d4, labels_v)\n    acc5 = accuracy(d5, labels_v)\n    acc6 = accuracy(d6, labels_v)\n    final_acc = acc0+acc1+acc2+acc3+acc4+acc5+acc6\n    return acc0,acc1,acc2,acc3,acc4,acc5,acc6","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.446486Z","iopub.execute_input":"2024-09-19T16:48:39.446829Z","iopub.status.idle":"2024-09-19T16:48:39.458902Z","shell.execute_reply.started":"2024-09-19T16:48:39.446791Z","shell.execute_reply":"2024-09-19T16:48:39.457935Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"image_ext = '.jpg'\nlabel_ext = '.jpg'\nmodel_name = 'u2net'\nmodel_dir = os.path.join(os.getcwd(), 'saved_models', model_name + os.sep)\nbatch_size_train = 32\nbatch_size_val = 1\ntrain_num = 0\nval_num = 0","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.460118Z","iopub.execute_input":"2024-09-19T16:48:39.460432Z","iopub.status.idle":"2024-09-19T16:48:39.471316Z","shell.execute_reply.started":"2024-09-19T16:48:39.460390Z","shell.execute_reply":"2024-09-19T16:48:39.470389Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def names_from_folder(folder_path):\n    list = []\n    for image in os.listdir(folder_path):\n        list.append(os.path.join(folder_path,image))\n    return list\n\ntra_img_name_list = names_from_folder(train_img_folder)\ntra_lbl_name_list = names_from_folder(train_mask_folder)\n\ntest_img_name_list = names_from_folder(test_img_folder)\ntest_lbl_name_list = names_from_folder(test_mask_folder)\n\nval_img_name_list = names_from_folder(val_img_folder)\nval_lbl_name_list = names_from_folder(val_mask_folder)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.482727Z","iopub.execute_input":"2024-09-19T16:48:39.483118Z","iopub.status.idle":"2024-09-19T16:48:39.579795Z","shell.execute_reply.started":"2024-09-19T16:48:39.483069Z","shell.execute_reply":"2024-09-19T16:48:39.578927Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"---\")\nprint(\"train images: \", len(tra_img_name_list))\nprint(\"train labels: \", len(tra_lbl_name_list))\nprint(\"---\")\nprint(\"test images: \", len(test_img_name_list))\nprint(\"test labels: \", len(test_lbl_name_list))\nprint(\"---\")\nprint(\"valid images: \", len(val_img_name_list))\nprint(\"valid labels: \", len(val_lbl_name_list))\nprint(\"---\")\n\ntrain_num = len(tra_img_name_list)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.580958Z","iopub.execute_input":"2024-09-19T16:48:39.581306Z","iopub.status.idle":"2024-09-19T16:48:39.588067Z","shell.execute_reply.started":"2024-09-19T16:48:39.581270Z","shell.execute_reply":"2024-09-19T16:48:39.586943Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"---\ntrain images:  13746\ntrain labels:  13746\n---\ntest images:  1726\ntest labels:  1726\n---\nvalid images:  1940\nvalid labels:  1940\n---\n","output_type":"stream"}]},{"cell_type":"code","source":"class Rescale2(object):\n\n    def __init__(self, output_size):\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        elif isinstance(output_size, tuple) and len(output_size) == 2:\n            self.output_size = output_size\n        else:\n            raise ValueError(\"output_size should be an int or a tuple of two integers\")\n\n    def __call__(self, sample):\n        imidx, image, label = sample['imidx'], sample['image'], sample['label']\n\n        if random.random() >= 0.5:\n            image = image[:, ::-1]  # Flip image horizontally\n            label = label[:, ::-1]  # Flip label horizontally\n\n        h, w = image.shape[:2]\n        new_h, new_w = self.output_size\n\n        # Resize the image and label\n        img = transform.resize(image, (new_h, new_w), mode='reflect', anti_aliasing=True)\n        lbl = transform.resize(label, (new_h, new_w), mode='constant', order=0, preserve_range=True)\n\n        return {'imidx': imidx, 'image': img, 'label': lbl}","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.589397Z","iopub.execute_input":"2024-09-19T16:48:39.589725Z","iopub.status.idle":"2024-09-19T16:48:39.598783Z","shell.execute_reply.started":"2024-09-19T16:48:39.589692Z","shell.execute_reply":"2024-09-19T16:48:39.597832Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torchvision.transforms as transforms\nfrom skimage import color\n\nclass ToTensorLab2(object):\n    \"\"\"Convert ndarrays in sample to Tensors and apply color space transformations.\"\"\"\n\n    def __init__(self, flag=0):\n        self.flag = flag\n\n    def __call__(self, sample):\n        imidx, image, label = sample['imidx'], sample['image'], sample['label']\n\n        # Normalize label to range [0,1] if label has any non-zero values\n        # if np.max(label) >= 1e-6:\n        #     label = label / np.max(label)\n\n        # Apply transformations based on the flag\n        if self.flag == 2:  # RGB + Lab colors\n            tmpImg = self.apply_rgb_lab_transform(image)\n        elif self.flag == 1:  # Lab color only\n            tmpImg = self.apply_lab_transform(image)\n        else:  # RGB color only\n            tmpImg = self.apply_rgb_transform(image)\n        \n        label[label <= 128] = 0\n        label[label > 128] = 1\n        tmpLbl = label.transpose((2, 0, 1))  # Reformat label to (C, H, W)\n\n        return {'imidx': torch.from_numpy(imidx), \n                'image': torch.from_numpy(tmpImg), \n                'label': torch.from_numpy(tmpLbl)}\n\n    def apply_rgb_transform(self, image):\n        \"\"\"Apply RGB normalization using torchvision.transforms.\"\"\"\n        if image.shape[2] == 1:  # Handle grayscale image\n            image = np.repeat(image, 3, axis=2)\n\n        image = image / np.max(image)  # Normalize image to range [0, 1]\n\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n        return transform(image).numpy()\n\n    def apply_lab_transform(self, image):\n        \"\"\"Convert the image to Lab color space and normalize.\"\"\"\n        if image.shape[2] == 1:  # Handle grayscale image\n            image = np.repeat(image, 3, axis=2)\n\n        image[image <= 128] = 0\n        image[image > 128] = 1\n\n        # Convert image to Lab color space\n        # lab_image = color.rgb2lab(image)\n        \n        # Normalize each channel to range [0, 1] and then standardize\n        # for i in range(3):\n        #     lab_image[:, :, i] = (lab_image[:, :, i] - np.min(lab_image[:, :, i])) / (np.max(lab_image[:, :, i]) - np.min(lab_image[:, :, i]))\n        #     lab_image[:, :, i] = (lab_image[:, :, i] - np.mean(lab_image[:, :, i])) / np.std(lab_image[:, :, i])\n        return image.transpose((2, 0, 1))\n\n    def apply_rgb_lab_transform(self, image):\n        \"\"\"Convert the image to both RGB and Lab color spaces, then concatenate.\"\"\"\n        if image.shape[2] == 1:  # Handle grayscale image\n            image = np.repeat(image, 3, axis=2)\n\n        # RGB normalization\n        rgb_normalized = self.apply_rgb_transform(image).transpose(1, 2, 0)  \n\n        # Lab transformation\n        lab_transformed = self.apply_lab_transform(image).transpose(1, 2, 0)  \n\n        # Concatenate RGB and Lab\n        combined = np.concatenate((rgb_normalized, lab_transformed), axis=2)\n\n        return combined.transpose((2, 0, 1))  # Return in (C, H, W) format\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.600319Z","iopub.execute_input":"2024-09-19T16:48:39.600716Z","iopub.status.idle":"2024-09-19T16:48:39.616975Z","shell.execute_reply.started":"2024-09-19T16:48:39.600670Z","shell.execute_reply":"2024-09-19T16:48:39.616089Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset = SalObjDataset(\n    img_name_list=tra_img_name_list,\n    lbl_name_list=tra_lbl_name_list,\n    transform=transforms.Compose([\n        Rescale2(256),\n        ToTensorLab2()]))\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n\n\ntest_dataset = SalObjDataset(\n    img_name_list=test_img_name_list,\n    lbl_name_list=test_lbl_name_list,\n    transform=transforms.Compose([\n        Rescale2(256),\n        ToTensorLab2()]))\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n\n\nval_dataset = SalObjDataset(\n    img_name_list=val_img_name_list,\n    lbl_name_list=val_lbl_name_list,\n    transform=transforms.Compose([\n        Rescale2(256),\n        ToTensorLab2()]))\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.618121Z","iopub.execute_input":"2024-09-19T16:48:39.618530Z","iopub.status.idle":"2024-09-19T16:48:39.632267Z","shell.execute_reply.started":"2024-09-19T16:48:39.618487Z","shell.execute_reply":"2024-09-19T16:48:39.631346Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    model.cuda()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:39.633382Z","iopub.execute_input":"2024-09-19T16:48:39.633778Z","iopub.status.idle":"2024-09-19T16:48:39.855422Z","shell.execute_reply.started":"2024-09-19T16:48:39.633733Z","shell.execute_reply":"2024-09-19T16:48:39.854584Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.autograd import Variable\n\nmetrics = {\n    'loss':None, 'loss0': None, 'loss1': None, 'loss2': None, 'loss3': None, 'loss4': None, 'loss5': None, 'loss6': None,\n    'dice0': None, 'dice1': None, 'dice2': None, 'dice3': None, 'dice4': None, 'dice5': None, 'dice6': None,\n    'acc0': None, 'acc1': None, 'acc2': None, 'acc3': None, 'acc4': None, 'acc5': None, 'acc6': None\n}\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize variables\nite_num = 0\nepoch_num = 1\n\nfor epoch in range(epoch_num):\n    model.train()\n\n    # Initialize running sums for each metric\n    running_loss = 0.0\n    running_loss0 = 0.0\n    running_loss1 = 0.0\n    running_loss2 = 0.0\n    running_loss3 = 0.0\n    running_loss4 = 0.0\n    running_loss5 = 0.0\n    running_loss6 = 0.0\n    running_dice0 = 0.0\n    running_dice1 = 0.0\n    running_dice2 = 0.0\n    running_dice3 = 0.0\n    running_dice4 = 0.0\n    running_dice5 = 0.0\n    running_dice6 = 0.0\n    running_acc0 = 0.0\n    running_acc1 = 0.0\n    running_acc2 = 0.0\n    running_acc3 = 0.0\n    running_acc4 = 0.0\n    running_acc5 = 0.0\n    running_acc6 = 0.0\n    \n    \n   \n    total_batches = 0  # Counter for the number of batches\n\n    for i, data in enumerate(train_dataloader):\n        ite_num += 1\n        total_batches += 1\n\n        inputs, labels = data['image'], data['label']\n        inputs = inputs.type(torch.FloatTensor)\n        labels = labels.type(torch.FloatTensor)\n\n        # Move to GPU if available\n        if torch.cuda.is_available():\n            inputs_v = Variable(inputs.to(device), requires_grad=False)\n            labels_v = Variable(labels.to(device), requires_grad=False)\n        else:\n            inputs_v = Variable(inputs, requires_grad=False)\n            labels_v = Variable(labels, requires_grad=False)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        d0, d1, d2, d3, d4, d5, d6 = model(inputs_v)\n        loss0 ,loss1 , loss2 , loss3 , loss4 , loss5 , loss6, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n        dice0,dice1,dice2,dice3,dice4,dice5,dice6 = muti_dice_coef_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n        acc0,acc1,acc2,acc3,acc4,acc5,acc6 = multi_accuracy_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        # Accumulate the metrics\n        running_loss += loss.data.item()\n        running_loss0 += loss0.data.item()\n        running_loss1 += loss1.data.item()\n        running_loss2 += loss2.data.item()\n        running_loss3 += loss3.data.item()\n        running_loss4 += loss4.data.item()\n        running_loss5 += loss5.data.item()\n        running_loss6 += loss6.data.item()\n        running_dice0 += dice0.data.item()\n        running_dice1 += dice1.data.item()\n        running_dice2 += dice2.data.item()\n        running_dice3 += dice3.data.item()\n        running_dice4 += dice4.data.item()\n        running_dice5 += dice5.data.item()\n        running_dice6 += dice6.data.item()\n        running_acc0 += acc0.data.item()\n        running_acc1 += acc1.data.item()\n        running_acc2 += acc2.data.item()\n        running_acc3 += acc3.data.item()\n        running_acc4 += acc4.data.item()\n        running_acc5 += acc5.data.item()\n        running_acc6 += acc6.data.item()\n        \n        del d0, d1, d2, d3, d4, d5, d6, loss0 ,loss1 , loss2 , loss3 , loss4 , loss5 , loss6, loss,dice0,dice1,dice2,dice3,dice4,dice5,dice6,acc0,acc1,acc2,acc3,acc4,acc5,acc6\n\n    # Calculate averages for the epoch\n    \n    \n\n    avg_loss = running_loss / total_batches\n    avg_loss0 = running_loss0 / total_batches\n    avg_loss1 = running_loss1 / total_batches\n    avg_loss2 = running_loss2 / total_batches\n    avg_loss3 = running_loss3 / total_batches\n    avg_loss4 = running_loss4 / total_batches\n    avg_loss5 = running_loss5 / total_batches\n    avg_loss6 = running_loss6 / total_batches\n    avg_dice0 = running_dice0 / total_batches\n    avg_dice1 = running_dice1 / total_batches\n    avg_dice2 = running_dice2 / total_batches\n    avg_dice3 = running_dice3 / total_batches\n    avg_dice4 = running_dice4 / total_batches\n    avg_dice5 = running_dice5 / total_batches\n    avg_dice6 = running_dice6 / total_batches\n    avg_acc0 = running_acc0 / total_batches\n    avg_acc1 = running_acc1 / total_batches\n    avg_acc2 = running_acc2 / total_batches\n    avg_acc3 = running_acc3 / total_batches\n    avg_acc4 = running_acc4 / total_batches\n    avg_acc5 = running_acc5 / total_batches\n    avg_acc6 = running_acc6 / total_batches\n    \n    \n    for i,j in zip(list(metrics.keys()),[avg_loss, avg_loss0, avg_loss1, avg_loss2, avg_loss3, avg_loss4, avg_loss5, avg_loss6,avg_dice0,avg_dice1,avg_dice2,avg_dice3,avg_dice4,avg_dice5,avg_dice6,avg_acc0,avg_acc1,avg_acc2,avg_acc3,avg_acc4,avg_acc5,avg_acc6 ]):\n        metrics[i]=j\n    \n    \n    # Print metrics for the epoch\n    print(f\"[Epoch: {epoch + 1}/{epoch_num}] \"\n          f\"Train Loss: {avg_loss:.4f}, \"\n          f\"Final Loss: {avg_loss0:.4f}, \"\n          f\"Final Dice Coefficient: {avg_dice0:.4f}, \"\n          f\"Final Accuracy: {avg_acc0:.4f}\")\n    \n    torch.save(model.state_dict(), f\"u2net_bce_train_epoch_{epoch + 1}_loss_{avg_loss:.4f}.pth\")\n\n\n    # Reset running sums for the next epoch\n    running_loss = 0.0\n    running_loss0 = 0.0\n    running_loss1 = 0.0\n    running_loss2 = 0.0\n    running_loss3 = 0.0\n    running_loss4 = 0.0\n    running_loss5 = 0.0\n    running_loss6 = 0.0\n    running_dice0 = 0.0\n    running_dice1 = 0.0\n    running_dice2 = 0.0\n    running_dice3 = 0.0\n    running_dice4 = 0.0\n    running_dice5 = 0.0\n    running_dice6 = 0.0\n    running_acc0 = 0.0\n    running_acc1 = 0.0\n    running_acc2 = 0.0\n    running_acc3 = 0.0\n    running_acc4 = 0.0\n    running_acc5 = 0.0\n    running_acc6 = 0.0\nimport pandas as pd\ndf = pd.DataFrame(metrics)\ndf.to_csv(\"Training_Data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:48:40.197997Z","iopub.status.idle":"2024-09-19T16:48:40.198399Z","shell.execute_reply.started":"2024-09-19T16:48:40.198196Z","shell.execute_reply":"2024-09-19T16:48:40.198216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"def normPRED(d):\n    ma = torch.max(d)\n    mi = torch.min(d)\n\n    dn = (d-mi)/(ma-mi)\n\n    return dn\n\ndef save_output(image_name,pred,d_dir):\n\n    predict = pred\n    predict = predict.squeeze()\n    predict_np = predict.cpu().data.numpy()\n\n    im = Image.fromarray(predict_np*255).convert('RGB')\n    img_name = image_name.split(os.sep)[-1]\n    image = io.imread(image_name)\n    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n\n    pb_np = np.array(imo)\n\n    aaa = img_name.split(\".\")\n    bbb = aaa[0:-1]\n    imidx = bbb[0]\n    for i in range(1,len(bbb)):\n        imidx = imidx + \".\" + bbb[i]\n\n    imo.save(d_dir+imidx+'.png')\n\n\ntest_metrics = {\n    'loss':None, 'loss0': None, 'loss1': None, 'loss2': None, 'loss3': None, 'loss4': None, 'loss5': None, 'loss6': None,\n    'dice0': None, 'dice1': None, 'dice2': None, 'dice3': None, 'dice4': None, 'dice5': None, 'dice6': None,\n    'acc0': None, 'acc1': None, 'acc2': None, 'acc3': None, 'acc4': None, 'acc5': None, 'acc6': None\n}\n\n\nfor i_test, data_test in enumerate(test_dataloader):\n\n    inputs_test = data_test['image']\n    inputs_test = inputs_test.type(torch.FloatTensor)\n\n    if torch.cuda.is_available():\n        inputs_test = Variable(inputs_test.cuda())\n    else:\n        inputs_test = Variable(inputs_test)\n\n    d1,d2,d3,d4,d5,d6,d7= model(inputs_test)\n    loss0 ,loss1 , loss2 , loss3 , loss4 , loss5 , loss6, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n    dice0,dice1,dice2,dice3,dice4,dice5,dice6 = muti_dice_coef_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n    acc0,acc1,acc2,acc3,acc4,acc5,acc6 = multi_accuracy_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n\n    for i,j in zip(list(metrics.keys()),[loss, loss0 ,loss1 , loss2 , loss3 , loss4 , loss5 , loss6, dice0,dice1,dice2,dice3,dice4,dice5,dice6 ,acc0,acc1,acc2,acc3,acc4,acc5,acc6 ]):\n        metrics[i]=j\n    \n    # normalization\n    pred = d1[:,0,:,:]\n    pred = normPRED(pred)\n\n    # save results to test_results folder\n    if not os.path.exists(prediction_dir):\n        os.makedirs(prediction_dir, exist_ok=True)\n    save_output(test_img_name_list[i_test],pred,prediction_dir)\n\n    del d1,d2,d3,d4,d5,d6,d7\nimport pandas as pd\ndf2 = pd.DataFrame(test_metrics)\ntest_metrics.to_csv(\"Testing_Data.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}